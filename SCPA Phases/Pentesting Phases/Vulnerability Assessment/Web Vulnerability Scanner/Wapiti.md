# Wapiti

TODO: Fill this info

## Setup

### Install Dependencies

- Kali Linux

```
$ sudo apt install nikto libjs-jquery python3-bs4 python3-importlib-metadata python3-mako python3-markupsafe python3-requests python3-six python3-socks python3-tld python3-yaswfp python3-httpx python3-aiocache python3-aiomcache python3-aiohttp python3-aiosqlite python3-arsenic python3-dnspython python3-h11 python3-httpcore python3-brotli python3-ntlm-auth python3-requests-ntlm python3-loguru python3-markupsafe mitmproxy python3-pyasn1 python3-sqlalchemy python3-humanize python3-exceptiongroup python3-anyio

$ pip3 install browser-cookie3
```

- Debian/Ubuntu based distros. Install [[Pentesting Phases/Vulnerability Assessment/Web Vulnerability Scanner/Nikto]] manually.

```
$ sudo apt install libjs-jquery python3-bs4 python3-importlib-metadata python3-mako python3-markupsafe python3-requests python3-six python3-socks python3-tld python3-yaswfp python3-httpx python3-aiohttp python3-aiosqlite python3-dnspython python3-h11 python3-httpcore python3-brotli python3-ntlm-auth python3-requests-ntlm python3-loguru python3-markupsafe mitmproxy python3-pyasn1 python3-sqlalchemy python3-humanize python3-exceptiongroup python3-anyio

$ sudo pip3 install --break-system-packages browser-cookie3 aiocache aiomcache arsenic sslyze
```

### Install Wapiti

- Run as root (without `sudo`)

```bash
git clone https://github.com/wapiti-scanner/wapiti /opt/vulnerability-analysis/wapiti

cat << EOF > /usr/local/bin/wapiti
#!/bin/sh
cd /opt/vulnerability-analysis/wapiti/bin/
python3 wapiti \$*
EOF
chmod 755 /usr/local/bin/wapiti

cat << EOF > /usr/local/bin/wapiti-getcookie
#!/bin/sh
cd /opt/vulnerability-analysis/wapiti/bin/
python3 wapiti-getcookie \$*
EOF
chmod 755 /usr/local/bin/wapiti-getcookie
```


## Help Menu

### Wapiti Scanner

```
$ wapiti -h

 ██╗    ██╗ █████╗ ██████╗ ██╗████████╗██╗██████╗
 ██║    ██║██╔══██╗██╔══██╗██║╚══██╔══╝██║╚════██╗
 ██║ █╗ ██║███████║██████╔╝██║   ██║   ██║ █████╔╝
 ██║███╗██║██╔══██║██╔═══╝ ██║   ██║   ██║ ╚═══██╗
 ╚███╔███╔╝██║  ██║██║     ██║   ██║   ██║██████╔╝
  ╚══╝╚══╝ ╚═╝  ╚═╝╚═╝     ╚═╝   ╚═╝   ╚═╝╚═════╝  
Wapiti 3.1.8 (wapiti-scanner.github.io)
usage: wapiti [-h] [-u URL] [--data data] [--scope {page,folder,domain,url,punk}] [-m MODULES_LIST] [--list-modules] [-l LEVEL] [-p PROXY_URL] [--tor] [--mitm-port PORT]
              [--headless {no,hidden,visible}] [--wait TIME] [-a CREDENTIALS] [--auth-user USERNAME] [--auth-password PASSWORD] [--auth-method {basic,digest,ntlm}]
              [--form-cred CREDENTIALS] [--form-user USERNAME] [--form-password PASSWORD] [--form-url URL] [--form-data DATA] [--form-enctype DATA] [--form-script FILENAME]
              [-c COOKIE_FILE] [--drop-set-cookie] [--skip-crawl] [--resume-crawl] [--flush-attacks] [--flush-session] [--store-session PATH] [--store-config PATH] [-s URL]
              [-x URL] [-r PARAMETER] [--skip PARAMETER] [-d DEPTH] [--max-links-per-page MAX] [--max-files-per-dir MAX] [--max-scan-time SECONDS] [--max-attack-time SECONDS]
              [--max-parameters MAX] [-S FORCE] [--tasks tasks] [--external-endpoint EXTERNAL_ENDPOINT_URL] [--internal-endpoint INTERNAL_ENDPOINT_URL] [--endpoint ENDPOINT_URL]
              [--dns-endpoint DNS_ENDPOINT_DOMAIN] [-t SECONDS] [-H HEADER] [-A AGENT] [--verify-ssl {0,1}] [--color] [-v LEVEL] [--log OUTPUT_PATH] [-f FORMAT] [-o OUTPUT_PATH]
              [-dr] [--no-bugreport] [--update] [--version]

Wapiti 3.1.8: Web application vulnerability scanner

options:
  -h, --help            show this help message and exit
  -u URL, --url URL     The base URL used to define the scan scope (default scope is folder)
  --data data           Urlencoded data to send with the base URL if it is a POST request
  --scope {page,folder,domain,url,punk}
                        Set scan scope
  -m MODULES_LIST, --module MODULES_LIST
                        List of modules to load
  --list-modules        List Wapiti attack modules and exit
  -l LEVEL, --level LEVEL
                        Set attack level
  -p PROXY_URL, --proxy PROXY_URL
                        Set the HTTP(S) proxy to use. Supported: http(s) and socks proxies
  --tor                 Use Tor listener (127.0.0.1:9050)
  --mitm-port PORT      Instead of crawling, launch an intercepting proxy on the given port
  --headless {no,hidden,visible}
                        Use a Firefox headless crawler for browsing (slower)
  --wait TIME           Wait the specified amount of seconds before analyzing a webpage (headless mode only)
  -a CREDENTIALS, --auth-cred CREDENTIALS
                        (DEPRECATED) Set HTTP authentication credentials
  --auth-user USERNAME  Set HTTP authentication username credentials
  --auth-password PASSWORD
                        Set HTTP authentication password credentials
  --auth-method {basic,digest,ntlm}
                        Set the HTTP authentication method to use
  --form-cred CREDENTIALS
                        (DEPRECATED) Set login form credentials
  --form-user USERNAME  Set login form credentials
  --form-password PASSWORD
                        Set password form credentials
  --form-url URL        Set login form URL
  --form-data DATA      Set login form POST data
  --form-enctype DATA   Set enctype to use to POST form data to form URL
  --form-script FILENAME
                        Use a custom Python authentication plugin
  -c COOKIE_FILE, --cookie COOKIE_FILE
                        Set a JSON cookie file to use. You can also pass 'firefox' or 'chrome' to load cookies from your browser.
  --drop-set-cookie     Ignore Set-Cookie header from HTTP responses
  --skip-crawl          Don't resume the scanning process, attack URLs scanned during a previous session
  --resume-crawl        Resume the scanning process (if stopped) even if some attacks were previously performed
  --flush-attacks       Flush attack history and vulnerabilities for the current session
  --flush-session       Flush everything that was previously found for this target (crawled URLs, vulns, etc)
  --store-session PATH  Directory where to store attack history and session data.
  --store-config PATH   Directory where to store configuration databases.
  -s URL, --start URL   Adds a url to start scan with
  -x URL, --exclude URL
                        Adds a url to exclude from the scan
  -r PARAMETER, --remove PARAMETER
                        Remove this parameter from urls
  --skip PARAMETER      Skip attacking given parameter(s)
  -d DEPTH, --depth DEPTH
                        Set how deep the scanner should explore the website
  --max-links-per-page MAX
                        Set how many (in-scope) links the scanner should extract for each page
  --max-files-per-dir MAX
                        Set how many pages the scanner should explore per directory
  --max-scan-time SECONDS
                        Set how many seconds you want the scan to last (floats accepted)
  --max-attack-time SECONDS
                        Set how many seconds you want each attack module to last (floats accepted)
  --max-parameters MAX  URLs and forms having more than MAX input parameters will be erased before attack.
  -S FORCE, --scan-force FORCE
                        Easy way to reduce the number of scanned and attacked URLs. Possible values: paranoid, sneaky, polite, normal, aggressive, insane
  --tasks tasks         Number of concurrent tasks to use for the exploration (crawling) of the target.
  --external-endpoint EXTERNAL_ENDPOINT_URL
                        Url serving as endpoint for target
  --internal-endpoint INTERNAL_ENDPOINT_URL
                        Url serving as endpoint for attacker
  --endpoint ENDPOINT_URL
                        Url serving as endpoint for both attacker and target
  --dns-endpoint DNS_ENDPOINT_DOMAIN
                        Domain serving as DNS endpoint for Log4Shell attack
  -t SECONDS, --timeout SECONDS
                        Set timeout for requests
  -H HEADER, --header HEADER
                        Set a custom header to use for every requests
  -A AGENT, --user-agent AGENT
                        Set a custom user-agent to use for every requests
  --verify-ssl {0,1}    Set SSL check (default is no check)
  --color               Colorize output
  -v LEVEL, --verbose LEVEL
                        Set verbosity level (0: quiet, 1: normal, 2: verbose)
  --log OUTPUT_PATH     Output log file
  -f FORMAT, --format FORMAT
                        Set output format. Supported: csv, html, json, txt, xml. Default is html.
  -o OUTPUT_PATH, --output OUTPUT_PATH
                        Output file or folder
  -dr, --detailed-report
                        HTTP responses will appear in the generated report
  --no-bugreport        Don't send automatic bug report when an attack module fails
  --update              Update Wapiti attack modules and exit
  --version             Show program's version number and exit
```

### Wapiti GetCookie

```
$ wapiti-getcookie -h 
usage: wapiti-getcookie [-h] -u URL -c COOKIE [-p PROXY] [--tor] [-a CREDENTIALS] [--auth-user USERNAME] [--auth-password PASSWORD] [--auth-method {basic,digest,ntlm}]
                        [--form-data DATA] [--form-enctype DATA] [--headless {no,hidden,visible}] [-A AGENT] [-H HEADER]

Wapiti-getcookie: An utility to grab cookies from a webpage

options:
  -h, --help            show this help message and exit
  -u URL, --url URL     First page to fetch for cookies
  -c COOKIE, --cookie COOKIE
                        Cookie file in Wapiti JSON format where cookies will be stored
  -p PROXY, --proxy PROXY
                        Address of the proxy server to use
  --tor                 Use Tor listener (127.0.0.1:9050)
  -a CREDENTIALS, --auth-cred CREDENTIALS
                        (DEPRECATED) Set HTTP authentication credentials
  --auth-user USERNAME  Set HTTP authentication credentials
  --auth-password PASSWORD
                        Set HTTP authentication credentials
  --auth-method {basic,digest,ntlm}
                        Set the authentication type to use
  --form-data DATA      Set login form POST data
  --form-enctype DATA   Set enctype to use to POST form data to form URL
  --headless {no,hidden,visible}
                        Use a Firefox headless crawler for browsing (slower)
  -A AGENT, --user-agent AGENT
                        Set a custom user-agent to use for every requests
  -H HEADER, --header HEADER
                        Set a custom header to use for every requests
```

## Usage

`$ wapiti -u <URL> -d <depth>`

`$ wapiti -u <URL> -S <paranoid | sneaky | polite | normal | aggressive | insane>`

`$ wapiti -u <URL> --list-modules`

`$ wapiti -u <URL> -m <module_1>,<module_n>`

### Authentication Methods

`$ wapiti -u <URL> --form-user <username> --form-password <password>`

`$ wapiti -u <URL> -c "<chrome | firefox>"`

`$ wapiti -u <URL> -l <level>`

`$ wapiti -u <URL> -f txt -o wapiti-vulnerability-assessment.txt`

## Use Cases

### SQL Injection

`$ wapiti -u <URL> -m sql,timesql`

### XSS

`$ wapiti -u <URL> -m permanentxss,xss`

### Path Traversal

`$ wapiti -u <URL> -m file`

### Command Injection

`$ wapiti -u <URL> -m exec,shellshock`

### File Upload

`$ wapiti -u <URL> -m upload,methods`

### XXE Injection

`$ wapiti -u <URL> -m xxe`

### Sensitive Data

`$ wapiti -u <URL> -m backup,buster`

### Content Management System (CMS)

- Wordpress

`$ waptiti -u <URL> -m wp_enum`

- Drupal

`$ waptiti -u <URL> -m drupal`

---
## References

- [Wapiti](https://wapiti-scanner.github.io/)