# OpenConnect

## 01 - Client Setup

```
$ sudo apt install -y openconnect
```

## 02 - Usage

```
# openconnect http[s]://<VPN_server_IP> --protocol=<anyconnect | nc | gp | pulse | f5 | fortinet | array> --os=linux-64 --passwd-on-stdin <<< <password>
```

## 03 - OPSEC Considerations

Spoof the hostname, user agent (refer to this [[07 - Tactics & Techniques & Procedures (TTPs) Phases/C - Initial Access/0x00 - Exploitation/0xF - Remote Services Exploitation/Network Ports/VPN/Helpers/User Agents|section]]), and along the operating system to make the VPN appliance recognize that it's not an `openconnect` client nor Linux.

```
# openconnect http[s]://<VPN_server_IP> --protocol=<anyconnect | nc | gp | pulse | f5 | fortinet | array> --os=win --local-hostname="<hostname>" --passwd-on-stdin <<< <password>

# openconnect http[s]://<VPN_server_IP> --protocol=<anyconnect | nc | gp | pulse | f5 | fortinet | array> --useragent="<user_agent>" --local-hostname="<hostname>" --passwd-on-stdin <<< <password>
```

## 04 - Scenarios

### 4.1 - Connecting to the VPS as SOCKS Proxy (most recommended)

```
$ ssh -NfqD 1080 <username>@<IP>
```

Then specify the SOCKS Proxy IP address and port to authenticate.

```
# openconnect http[s]://<VPN_server_IP> -P socks5://localhost:1080 --protocol=<anyconnect | nc | gp | pulse | f5 | fortinet | array> --os=linux-64 --passwd-on-stdin <<< <password>
```

You can also pass the credentials to an existing SOCKS server instead of a VPS.

```
# openconnect http[s]://<VPN_server_IP> -P socks5://<username>:<password>@<SOCKS5_IP>:<SOCKS5_PORT> --protocol=<anyconnect | nc | gp | pulse | f5 | fortinet | array> --os=linux-64 --passwd-on-stdin <<< <password>
```

### 4.2 - Connecting to the VPS as SSH Local Port Forwarding

```
$ ssh -NTfCqL <local_PORT>:<VPN_server_IP>:<bind_VPN_PORT> <username>@<IP>
```

Then authenticate the VPN appliance to join the network.

```
# openconnect http[s]://<VPS_IP>:<local_PORT> --protocol=<anyconnect | nc | gp | pulse | f5 | fortinet | array> --os=linux-64 --passwd-on-stdin <<< <password>
```

### 4.3 - Connecting to the VPS as TLS Local Port Forwarding

Launch a listener on any port as a plain text server. Upon connection, connect to VPN appliances IP address using SSL and forward server traffic.

```
$ ncat -lp <local_PORT> -c 'ncat --ssl <VPN_server_IP> <VPN_PORT>' --keep-open -o session.log
```

Then authenticate the VPN appliance to join the network.

```
# openconnect http://<VPS_IP>:<local_PORT> --protocol=<anyconnect | nc | gp | pulse | f5 | fortinet | array> --os=linux-64 --passwd-on-stdin <<< <password>
```

### 4.4 - Setting up a Pseudo-VPN SSH server in the VPS to pivot off to VPN appliance (recommended)

TODO: Setup a VPN service in the VPS as a TCP protocol to connect the VPN appliance of the enterprise network.

Only if configured as UDP protocol for most cases. The solution as illustrated from the figure is to use VPS as a proxy then pivot with SSH to bind the TUN network interface.

Attacker VM (Torrified with Whonix) -> VPS (Pivot via SSH) -> VPN Appliance (UDP protocol)

Using SSH Server as a Pseudo-VPN Network

```
https://www.youtube.com/watch?v=SHSqFAdd41A

https://gist.github.com/pinkeen/bc65c1b3beaa448ea5439e9688605866
```

### 4.5 - SSH Tunneling to a VPS (as a VPN client) to pivot to a VPN server (Expert)

TODO: Use docker to test if it won't lock out the VPS

Let's say the scenario when you SSH tunnel (Attacker) to the VPS (the VPN client) that has established connection the VPN server (the enterprise network) because your virtual machine has been configured in the Whonix gateway network.

The problem is that when you connect to your VPS by its public IP address, the VPN changes the routing table of your VPS, so that the packets that are sent back to you go through the VPN instead of the public interface. This causes the connection to fail, because the VPN server does not know how to reach your computer.

The solution is to add a special rule and a route for your public IP address, so that the packets that are sent from your VPS to your public IP address go through the public interface instead of the VPN. This way, the connection can succeed, because the packets can reach your computer directly.

The commands that you need to run on your VPS are:

```
# ip rule add from <VPS_IP> table 128 

# ip route add table 128 to <VPS_SUBNET>/<CIDR> dev <network_inteface>

# ip route add table 128 default via <VPS_GATEWAY>
```

- Which can be done in a script. Execute it as root (without `sudo`). (TODO: modify the subnet part)

```bash
IP=$(ip route get 1 | grep -Po '(?<=src )(\S+)')
SUBNET=$(ip route get 1 | grep -Po '(?<=src )(\S+)')
NETWORK_INTERFACE=$(ip -4 route ls | grep default | grep -Po '(?<=dev )(\S+)')
GATEWAY=$(ip -4 route ls | grep default | grep -Po '(?<=via )(\S+)')


ip rule add from "${IP}" table 128
ip route add table 128 to "${SUBNET}"/32 dev "${NETWORK_INTERFACE}"
ip route add table 128 default via "${GATEWAY}"
```

Where `<VPS_IP>` is your VPS's public IP address, `<VPS_SUBNET>/<CIDR>` is the subnet of your VPS's public IP address, `ethX` or `enp7s0` is the name of your VPS's public interface, and `<VPS_GATEWAY>` is the default gateway of your VPS's public interface.

For example, if your VPS's public IP address is 172.16.9.132, the subnet is 172.16.9.0/24, the public interface is eth0, and the default gateway is 172.16.9.1, then the commands are:

```
# ip rule add from 172.16.9.132 table 128
# ip route add table 128 to 172.16.9.0/32 dev eth0
# ip route add table 128 default via 172.16.9.1
```

These commands create a new routing table (table 128) that has only one route: the default route via the public interface. Then, they add a rule that says that any packet that comes from the public IP address should use this table instead of the main table. This way, the packets that are sent from your VPS to your public IP address will use the public interface and not the VPN.

To delete the special rule and the route of the public IP address, you need to use the `ip rule del` and `ip route del` commands with the same parameters that you used to add them.


We'll be using the previous example:

```
# ip rule delete from 172.16.9.132 table 128
# ip route delete table 128 to 172.16.9.0/32 dev eth0
# ip route delete table 128 default via 172.16.9.1
```

Alternatively, you can delete the rule and the route using their priority numbers. To find the priority numbers, you can use the `ip rule show` command. For example, if the output looks like this:

- Syntax

```
# ip rule show
0: from all lookup local
<priority_number>: from <VPS_IP> lookup 128
32766: from all lookup main
32767: from all lookup default
```

- Usage

```
# ip rule show
0: from all lookup local
32765: from 172.16.9.132 lookup 128
32766: from all lookup main
32767: from all lookup default
```

You can see that the rule for the `table 128` has the `priority` number `32765`. You can delete it using this command:

- Syntax

```
# ip rule delete priority <priority_number>
```

- Usage

```
# ip rule delete priority 32765
```

To delete the route for the `table 128`, you can use the `ip route flush` command with the table number. For example:

```
# ip route flush table 128
```

This will delete all the routes in the table 128, including the default route.

Note that this solution will apply to all ports, not just ssh. This means that any service that is running on your VPS will be accessible from your public IP address. If you want to restrict the access to only ssh, you need to add some firewall rules using iptables. The commands are:

```
# iptables -A INPUT -d <VPS_IP> -p tcp --dport <SSH_PORT> -j ACCEPT

# iptables -A INPUT -d <VPS_IP> -j DROP
```

These commands allow only ssh traffic (port 22) to your public IP address, and drop everything else. This way, you can connect to your VPS using ssh, but not using any other service such as, RDP (port 3389).

Note: When I run this on the VPS it hangs so I did a little research to what resolve the issue. Turns out I need to specify the routing rule for the VPS. Follow the instructions carefully otherwise it'll hang up and authenticating with SSH won't work. SO BE CAREFUL because this includes OpenVPN and Wireguard.

- Add a rule for the public VPS IP.

```
# ip address | grep inet

# ip rule add table 128 from <VPS_inet_IP>

# ip rule add table 128 from $(ip route get 1 | grep -Po '(?<=src )(\S+)')
```

- Add a static route of the VPS IP subnet mask (TODO: modify the subnet part)

```
# ip route add table 128 to <VPS_IP>/<CIDR> dev <WAN_interface>

# ip route add table 128 to $(ip route get 1 | grep -Po '(?<=src )(\S+)')/<CIDR> dev $(ip -4 route ls | grep default | grep -Po '(?<=dev )(\S+)')
```

- Add a gateway route

```
# ip -4 route | grep default

# ip route add table 128 default via <VPS_gateway>

# ip route add table 128 default via $(ip -4 route ls | grep default | grep -Po '(?<=via )(\S+)')
```

- Add a firewall rule

```
# iptables -A INPUT -d <VPS_inet_IP> -p tcp --dport <SSH_PORT> -j ACCEPT

# iptables -A INPUT -d <VPS_inet_IP> -j DROP

# ufw allow ssh <SSH_PORT>/tcp
```

Connect to a VPN

```
$ sudo openconnect http[s]://<vpn_server_IP> --protocol=fortinet -u <username> --passwd-on-stdin <<< <password>
```

IPv6 equivalent (TODO: Figure this out later  in the future)

```
# ip -6 rule add from 2a01:7e00::x:x:x:x table 129

# ip -6 route add table 129 to 2a01:7e00::/64 dev eth0

# ip -6 route add table 129 default via fe80::1 dev eth0
```

Delete static IP route rules first disconnect the VPN connection for `openconnect` since `CTRL+C` may not work.

```
$ pgrep openconnect | while read line; do sudo kill -9 $line; done
```

---
## References

- [[03 - Local Port Forwarding|Pivoting: SSH Local Port Forwarding]]

- [[Port Forward TLS|Pivoting: Ncat TLS Local Port Forwarding]]

- [bing0o: vpn_on_vps](https://github.com/bing0o/bash_scripting/blob/master/vpn_on_vps.sh)